---
title: "Using Prior Weights with XGboost"
author: "Sam Castillo"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r message = F, warning = F}
library(xgboost)
library(tidyverse)
```

```{r}
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')

dtrain <- xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
dtest <- xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)
watchlist <- list(train = dtrain, eval = dtest)

## A simple xgb.train example:
param <- list(max_depth = 2, eta = 0.05, verbose = 0, nthread = 2,
              objective = "binary:logistic", eval_metric = "auc")

baseline <- xgb.train(param, dtrain, nrounds = 5, watchlist)
```

```{r}
df <- agaricus.test$data %>% as.matrix() %>% as_tibble() %>% 
  mutate(
    y_hat = predict(baseline, agaricus.test$data),
    y = agaricus.test$label)

df %>% glimpse()
```

```{r}

df %>% 
  group_by(`odor=almond`) %>% 
  summarise(
    avg_pred = mean(y_hat)
  )
```

Suppose that we had prior information that we wished to incorporate.

```{r}
#set the prior weight for all almond-smelling mushrooms to be 50%
prior_probabilities <- agaricus.train$data %>% 
  as.matrix() %>% 
  as_tibble() %>% 
  transmute(prior_wts = ifelse(`cap-shape=bell` == 1, 
                               yes = 0.1, 
                               no = 0.9)) %>% 
  unlist() %>% 
  as.numeric()

```


```{r}
setinfo(dtrain, "base_margin", log(prior_probabilities))
prior_weighted <- xgb.train(param, dtrain, nrounds = 30, watchlist)

agaricus.test$data %>% as.matrix() %>% as_tibble() %>% 
  mutate(
    y_hat_baseline = predict(baseline, agaricus.test$data),
    y_hat_prior_wtd = predict(prior_weighted, agaricus.test$data),
    y = agaricus.test$label) %>% 
   group_by(`cap-shape=bell`) %>% 
  summarise(
    avg_baseline = mean(y_hat_baseline),
    avg_wtd = mean(y_hat_prior_wtd),
    avg_y = mean(y)
  ) 
```

